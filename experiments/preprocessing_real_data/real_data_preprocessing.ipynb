{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1679ce7",
   "metadata": {},
   "source": [
    "# Preprocessing of real data\n",
    "\n",
    "This notebook allows to create hourly data with precipitation, streamflow, potential evapotranspiration and date from the following files:\n",
    "\n",
    "- MeteoSwiss combiprecip product\n",
    "- Hourly streamflow data\n",
    "- Daily minimum, maximal and mean temperature to compute the daily potential evapotranspiration, which is then distributed evenly over 24 hours and saved at an hourly resolution.\n",
    "- Daily precipitation and streamflow data is also used to fill some possible gaps in the hourly ones.\n",
    "\n",
    "/!\\ The Pyeto Python package should be downloaded from [here](https://github.com/woodcrafty/PyETo) if it is not already present in the root folder of your repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a11069",
   "metadata": {},
   "source": [
    "# START by dowloading the file 'data.zip' using the link below and extract it. Save the resulting 'data' folder in the folder 'experiments'.\n",
    "\n",
    "https://www.dropbox.com/scl/fi/mo4xg95ktj7yt09e1o78a/data.zip?rlkey=9m8e4nshv831g7q129c1vsy53&st=rgy8wp05&dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6550c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime, timedelta, date\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import pyeto\n",
    "\n",
    "\n",
    "ALL_GIS_IDs = ['44']\n",
    "\n",
    "\n",
    "def toYearFraction(date):\n",
    "    def sinceEpoch(date): # returns seconds since epoch\n",
    "        return (date.timestamp())\n",
    "    s = sinceEpoch\n",
    "\n",
    "    year = date.year\n",
    "    startOfThisYear = datetime(year=year, month=1, day=1)\n",
    "    startOfNextYear = datetime(year=year+1, month=1, day=1)\n",
    "\n",
    "    yearElapsed = s(date) - s(startOfThisYear)\n",
    "    yearDuration = s(startOfNextYear) - s(startOfThisYear)\n",
    "    fraction = yearElapsed/yearDuration\n",
    "\n",
    "    return date.year + fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4338517f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>0.082580</td>\n",
       "      <td>0.962813</td>\n",
       "      <td>13.472302</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.229430</td>\n",
       "      <td>0.162004</td>\n",
       "      <td>20050101000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354984</td>\n",
       "      <td>4.575424</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.077918</td>\n",
       "      <td>0.066220</td>\n",
       "      <td>20050101010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>0.044690</td>\n",
       "      <td>0.354984</td>\n",
       "      <td>5.555367</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.094607</td>\n",
       "      <td>0.056280</td>\n",
       "      <td>20050101020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>1.039622</td>\n",
       "      <td>15.512222</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.264169</td>\n",
       "      <td>0.178919</td>\n",
       "      <td>20050101030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.708286</td>\n",
       "      <td>10.640811</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.181210</td>\n",
       "      <td>0.127028</td>\n",
       "      <td>20050101040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155824</th>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20221106190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155825</th>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>20221106200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155826</th>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015260</td>\n",
       "      <td>0.425136</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>20221106210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155827</th>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20221106220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155828</th>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.72076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20221106230000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155829 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GIS_ID       min       max        sum     count      mean       std  \\\n",
       "0           44  0.082580  0.962813  13.472302  58.72076  0.229430  0.162004   \n",
       "1           44  0.000000  0.354984   4.575424  58.72076  0.077918  0.066220   \n",
       "2           44  0.044690  0.354984   5.555367  58.72076  0.094607  0.056280   \n",
       "3           44  0.060749  1.039622  15.512222  58.72076  0.264169  0.178919   \n",
       "4           44  0.035498  0.708286  10.640811  58.72076  0.181210  0.127028   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "155824      44  0.000000  0.000000   0.000000  58.72076  0.000000  0.000000   \n",
       "155825      44  0.000000  0.006075   0.002030  58.72076  0.000035  0.000457   \n",
       "155826      44  0.000000  0.015260   0.425136  58.72076  0.007240  0.004407   \n",
       "155827      44  0.000000  0.000000   0.000000  58.72076  0.000000  0.000000   \n",
       "155828      44  0.000000  0.000000   0.000000  58.72076  0.000000  0.000000   \n",
       "\n",
       "              datetime  \n",
       "0       20050101000000  \n",
       "1       20050101010000  \n",
       "2       20050101020000  \n",
       "3       20050101030000  \n",
       "4       20050101040000  \n",
       "...                ...  \n",
       "155824  20221106190000  \n",
       "155825  20221106200000  \n",
       "155826  20221106210000  \n",
       "155827  20221106220000  \n",
       "155828  20221106230000  \n",
       "\n",
       "[155829 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/real_data/polygons_CH1903_LV95_area_weighted_combiprecip/44.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66555a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_J = '../data/real_data/polygons_CH1903_LV95_area_weighted_combiprecip/'\n",
    "path_daily = '../data/real_data/Daily_Data/'\n",
    "path_Q  = '../data/real_data/hourly_streamflow/'\n",
    "file_catchprop = '../data/CH_Catchments_Geodata_MF_20221209.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a07685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUALITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quaternary Deposits  CH 1:25000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gridcode</td>\n",
       "      <td>gridcode</td>\n",
       "      <td>Gewaesser</td>\n",
       "      <td>Station</td>\n",
       "      <td>Betreiber</td>\n",
       "      <td>Flaeche [km2]</td>\n",
       "      <td>LAGE</td>\n",
       "      <td>WaterBalance</td>\n",
       "      <td>Hydrograph</td>\n",
       "      <td>Datenqualität</td>\n",
       "      <td>...</td>\n",
       "      <td>Alps_Sediments</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>artificial</td>\n",
       "      <td>other</td>\n",
       "      <td>alluvial</td>\n",
       "      <td>glacial</td>\n",
       "      <td>swamp</td>\n",
       "      <td>debris</td>\n",
       "      <td>landslide</td>\n",
       "      <td>waters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIS_ID</td>\n",
       "      <td>org_ID</td>\n",
       "      <td>Gewaesser</td>\n",
       "      <td>Station</td>\n",
       "      <td>Betreiber</td>\n",
       "      <td>EZG</td>\n",
       "      <td>1 = Alpine / 2 = Midlands / 3 = Other</td>\n",
       "      <td>1 = good / 2 = ok / 3 = poor</td>\n",
       "      <td>1 = good / 2 = ok / 3 = poor</td>\n",
       "      <td>INFO</td>\n",
       "      <td>...</td>\n",
       "      <td>sedimentary rocks</td>\n",
       "      <td>total</td>\n",
       "      <td>artificial</td>\n",
       "      <td>other</td>\n",
       "      <td>alluvial</td>\n",
       "      <td>glacial</td>\n",
       "      <td>swamp</td>\n",
       "      <td>debris</td>\n",
       "      <td>landslide</td>\n",
       "      <td>waters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>Aare</td>\n",
       "      <td>Brienzwiler</td>\n",
       "      <td>BAFU</td>\n",
       "      <td>554,0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hydropeaking</td>\n",
       "      <td>...</td>\n",
       "      <td>16,5</td>\n",
       "      <td>55,6</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,0</td>\n",
       "      <td>2,1</td>\n",
       "      <td>33,0</td>\n",
       "      <td>0,2</td>\n",
       "      <td>17,5</td>\n",
       "      <td>1,3</td>\n",
       "      <td>1,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2034</td>\n",
       "      <td>Broye</td>\n",
       "      <td>Payerne, Caserne d'aviation</td>\n",
       "      <td>BAFU</td>\n",
       "      <td>417,8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13,0</td>\n",
       "      <td>75,9</td>\n",
       "      <td>0,7</td>\n",
       "      <td>3,7</td>\n",
       "      <td>4,7</td>\n",
       "      <td>54,0</td>\n",
       "      <td>3,5</td>\n",
       "      <td>6,0</td>\n",
       "      <td>3,1</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Durach</td>\n",
       "      <td>Schaffhausen</td>\n",
       "      <td>SCHAFFHAUSEN</td>\n",
       "      <td>44,9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0,0</td>\n",
       "      <td>34,9</td>\n",
       "      <td>0,2</td>\n",
       "      <td>0,2</td>\n",
       "      <td>12,6</td>\n",
       "      <td>3,9</td>\n",
       "      <td>0,0</td>\n",
       "      <td>17,6</td>\n",
       "      <td>0,4</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Durach</td>\n",
       "      <td>Merishausen</td>\n",
       "      <td>SCHAFFHAUSEN</td>\n",
       "      <td>10,6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0,0</td>\n",
       "      <td>34,4</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,2</td>\n",
       "      <td>10,9</td>\n",
       "      <td>1,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>21,3</td>\n",
       "      <td>1,0</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fochtelgraben</td>\n",
       "      <td>Neunkirch</td>\n",
       "      <td>SCHAFFHAUSEN</td>\n",
       "      <td>6,5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0,0</td>\n",
       "      <td>82,7</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,0</td>\n",
       "      <td>26,5</td>\n",
       "      <td>0,0</td>\n",
       "      <td>0,1</td>\n",
       "      <td>51,2</td>\n",
       "      <td>4,9</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Halbach</td>\n",
       "      <td>Hallau</td>\n",
       "      <td>SCHAFFHAUSEN</td>\n",
       "      <td>10,7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0,0</td>\n",
       "      <td>73,9</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,0</td>\n",
       "      <td>21,0</td>\n",
       "      <td>8,2</td>\n",
       "      <td>0,0</td>\n",
       "      <td>41,5</td>\n",
       "      <td>3,0</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Schleitheimerbach</td>\n",
       "      <td>Talmühle</td>\n",
       "      <td>SCHAFFHAUSEN</td>\n",
       "      <td>30,8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0,0</td>\n",
       "      <td>48,6</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,0</td>\n",
       "      <td>14,4</td>\n",
       "      <td>1,7</td>\n",
       "      <td>0,0</td>\n",
       "      <td>30,2</td>\n",
       "      <td>2,2</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1                  2                            3    \\\n",
       "0         NaN       NaN                NaN                          NaN   \n",
       "1    gridcode  gridcode          Gewaesser                      Station   \n",
       "2      GIS_ID    org_ID          Gewaesser                      Station   \n",
       "3           0      2019               Aare                  Brienzwiler   \n",
       "4           1      2034              Broye  Payerne, Caserne d'aviation   \n",
       "..        ...       ...                ...                          ...   \n",
       "392       407       NaN             Durach                 Schaffhausen   \n",
       "393       408       NaN             Durach                  Merishausen   \n",
       "394       409       NaN      Fochtelgraben                    Neunkirch   \n",
       "395       410       NaN            Halbach                       Hallau   \n",
       "396       411       NaN  Schleitheimerbach                     Talmühle   \n",
       "\n",
       "              4              5                                      6    \\\n",
       "0             NaN            NaN                                QUALITY   \n",
       "1       Betreiber  Flaeche [km2]                                   LAGE   \n",
       "2       Betreiber           EZG   1 = Alpine / 2 = Midlands / 3 = Other   \n",
       "3            BAFU          554,0                                      1   \n",
       "4            BAFU          417,8                                      2   \n",
       "..            ...            ...                                    ...   \n",
       "392  SCHAFFHAUSEN           44,9                                      3   \n",
       "393  SCHAFFHAUSEN           10,6                                      3   \n",
       "394  SCHAFFHAUSEN            6,5                                      3   \n",
       "395  SCHAFFHAUSEN           10,7                                      3   \n",
       "396  SCHAFFHAUSEN           30,8                                      3   \n",
       "\n",
       "                              7                             8    \\\n",
       "0                             NaN                           NaN   \n",
       "1                    WaterBalance                    Hydrograph   \n",
       "2    1 = good / 2 = ok / 3 = poor  1 = good / 2 = ok / 3 = poor   \n",
       "3                               3                           NaN   \n",
       "4                               1                           NaN   \n",
       "..                            ...                           ...   \n",
       "392                             2                           NaN   \n",
       "393                             2                           NaN   \n",
       "394                             2                           NaN   \n",
       "395                             1                           NaN   \n",
       "396                             2                           NaN   \n",
       "\n",
       "                9    ...                 149                              150  \\\n",
       "0               NaN  ...                 NaN  Quaternary Deposits  CH 1:25000   \n",
       "1     Datenqualität  ...      Alps_Sediments                            TOTAL   \n",
       "2              INFO  ...  sedimentary rocks                             total   \n",
       "3      hydropeaking  ...                16,5                             55,6   \n",
       "4               NaN  ...                13,0                             75,9   \n",
       "..              ...  ...                 ...                              ...   \n",
       "392             NaN  ...                 0,0                             34,9   \n",
       "393             NaN  ...                 0,0                             34,4   \n",
       "394             NaN  ...                 0,0                             82,7   \n",
       "395             NaN  ...                 0,0                             73,9   \n",
       "396             NaN  ...                 0,0                             48,6   \n",
       "\n",
       "            151    152       153       154    155     156        157     158  \n",
       "0           NaN    NaN       NaN       NaN    NaN     NaN        NaN     NaN  \n",
       "1    artificial  other  alluvial  glacial   swamp  debris  landslide  waters  \n",
       "2    artificial  other  alluvial  glacial   swamp  debris  landslide  waters  \n",
       "3           0,1    0,0       2,1      33,0    0,2    17,5        1,3     1,4  \n",
       "4           0,7    3,7       4,7      54,0    3,5     6,0        3,1     0,0  \n",
       "..          ...    ...       ...       ...    ...     ...        ...     ...  \n",
       "392         0,2    0,2      12,6       3,9    0,0    17,6        0,4     0,0  \n",
       "393         0,0    0,2      10,9       1,0    0,0    21,3        1,0     0,0  \n",
       "394         0,0    0,0      26,5       0,0    0,1    51,2        4,9     0,0  \n",
       "395         0,1    0,0      21,0       8,2    0,0    41,5        3,0     0,0  \n",
       "396         0,1    0,0      14,4       1,7    0,0    30,2        2,2     0,0  \n",
       "\n",
       "[397 rows x 159 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_catchprop, header=None,  engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20cae2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_catchprop, header=None,  engine='python')\n",
    "\n",
    "data_type = df.iloc[0,:]\n",
    "description = df.iloc[1,:]\n",
    "IDs = df.iloc[2,:]\n",
    "df = df.drop([0,1,2])\n",
    "rows_idx = list(df.iloc[:,0])\n",
    "\n",
    "df_info = df.iloc[:,[0,9]]\n",
    "df_info.columns = ['GIS_ID', 'INFO']\n",
    "\n",
    "categories = ['Area', 'Quality', 'Response', 'Climate', 'Altitude', 'Slope', 'runoff accumulation', \n",
    "              'storage capacity', 'permeability', 'waterlogging', 'thoroughness', 'land use',\n",
    "             'ground cover' ] + 5*['Geology'] + ['Quaternary Deposits']\n",
    "category = None\n",
    "category2feature = {'Area': []}\n",
    "count = 0\n",
    "\n",
    "for i in range(len(data_type)):\n",
    "    if type(data_type[i])!=str:\n",
    "        category2feature[categories[count]].append(IDs[i])\n",
    "    else:\n",
    "        count += 1\n",
    "        try:\n",
    "            category2feature[categories[count]].append(IDs[i])\n",
    "        except:\n",
    "            category2feature[categories[count]] = [IDs[i]]\n",
    "        \n",
    "features2idxcategory = {}\n",
    "for i,cat in enumerate(categories):\n",
    "    for feature in category2feature[cat]:\n",
    "        features2idxcategory[feature] = i\n",
    "df.columns = IDs\n",
    "\n",
    "\n",
    "df_catchment_names = df[list(IDs[:5])+['H_MIN','H_MAX', 'H_MEAN']]#df[list(IDs[:5])]\n",
    "df_catchment_names.head()\n",
    "\n",
    "\n",
    "df.columns = IDs\n",
    "gis_id = df['GIS_ID']\n",
    "df = df.drop(columns=['GIS_ID'])\n",
    "df.index = rows_idx\n",
    "\n",
    "df_infos = df.iloc[:,1:4]\n",
    "df_data = df.iloc[:,4:]\n",
    "df_data = df_data.drop(df_data.columns[[3, 4]],axis = 1)\n",
    "\n",
    "\n",
    "Betreiber2acronym = {'BAFU':'BAFU-',\n",
    "                     'AARGAU':'AG',\n",
    "                     'SOLOTHURN':'SO-',\n",
    "                     'BERN':'BE-',\n",
    "                     'BASEL LANDSCHAFT': 'BL-',\n",
    "                     'LUZERN':'LU-',\n",
    "                     'ZUERICH':'ZH-'}\n",
    "\n",
    "def get_acronym(serie):\n",
    "    res = []\n",
    "    for name in serie:\n",
    "        res.append(Betreiber2acronym[name])\n",
    "    return res\n",
    "df_catchment_names = df_catchment_names.dropna(subset=['org_ID'])\n",
    "df_catchment_names['catchment_name'] = get_acronym(df_catchment_names['Betreiber'].astype(str)) + df_catchment_names[\"org_ID\"]\n",
    "df_catchment_names.index = range(len(df_catchment_names['catchment_name']))\n",
    "df_catchment_names['catchment_name'] = df_catchment_names['catchment_name'].apply(lambda x: x.replace('_','-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c9f1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>org_ID</th>\n",
       "      <th>Gewaesser</th>\n",
       "      <th>Station</th>\n",
       "      <th>Betreiber</th>\n",
       "      <th>H_MIN</th>\n",
       "      <th>H_MAX</th>\n",
       "      <th>H_MEAN</th>\n",
       "      <th>catchment_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>Aare</td>\n",
       "      <td>Brienzwiler</td>\n",
       "      <td>BAFU</td>\n",
       "      <td>570</td>\n",
       "      <td>4273</td>\n",
       "      <td>2131</td>\n",
       "      <td>BAFU-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2034</td>\n",
       "      <td>Broye</td>\n",
       "      <td>Payerne, Caserne d'aviation</td>\n",
       "      <td>BAFU</td>\n",
       "      <td>440</td>\n",
       "      <td>1514</td>\n",
       "      <td>721</td>\n",
       "      <td>BAFU-2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2053</td>\n",
       "      <td>Drance</td>\n",
       "      <td>Martigny, Pont de Rossettan</td>\n",
       "      <td>BAFU</td>\n",
       "      <td>478</td>\n",
       "      <td>4312</td>\n",
       "      <td>2247</td>\n",
       "      <td>BAFU-2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2070</td>\n",
       "      <td>Emme</td>\n",
       "      <td>Emmenmatt, nur Hauptstation</td>\n",
       "      <td>BAFU</td>\n",
       "      <td>639</td>\n",
       "      <td>2221</td>\n",
       "      <td>1070</td>\n",
       "      <td>BAFU-2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2078</td>\n",
       "      <td>Poschiavino</td>\n",
       "      <td>Le Prese, stazione principale</td>\n",
       "      <td>BAFU</td>\n",
       "      <td>965</td>\n",
       "      <td>3891</td>\n",
       "      <td>2126</td>\n",
       "      <td>BAFU-2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>336</td>\n",
       "      <td>4329</td>\n",
       "      <td>Hintere Frenke</td>\n",
       "      <td>Reigoldswil</td>\n",
       "      <td>BASEL LANDSCHAFT</td>\n",
       "      <td>486</td>\n",
       "      <td>1168</td>\n",
       "      <td>735</td>\n",
       "      <td>BL-4329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>389</td>\n",
       "      <td>FG_0346</td>\n",
       "      <td>Aabach</td>\n",
       "      <td>Lenzburg</td>\n",
       "      <td>AARGAU</td>\n",
       "      <td>392</td>\n",
       "      <td>878</td>\n",
       "      <td>563</td>\n",
       "      <td>AGFG-0346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>391</td>\n",
       "      <td>4502</td>\n",
       "      <td>Stüsslingerbach</td>\n",
       "      <td>Lostorf</td>\n",
       "      <td>SOLOTHURN</td>\n",
       "      <td>416</td>\n",
       "      <td>957</td>\n",
       "      <td>575</td>\n",
       "      <td>SO-4502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>401</td>\n",
       "      <td>A093</td>\n",
       "      <td>Weisse Luetschine</td>\n",
       "      <td>Grindelwald</td>\n",
       "      <td>BERN</td>\n",
       "      <td>992</td>\n",
       "      <td>4107</td>\n",
       "      <td>2686</td>\n",
       "      <td>BE-A093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>402</td>\n",
       "      <td>A112</td>\n",
       "      <td>Schwarze Luetschine</td>\n",
       "      <td>Grindelwald</td>\n",
       "      <td>BERN</td>\n",
       "      <td>980</td>\n",
       "      <td>3745</td>\n",
       "      <td>2197</td>\n",
       "      <td>BE-A112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "2   GIS_ID   org_ID            Gewaesser                        Station  \\\n",
       "0        0     2019                 Aare                    Brienzwiler   \n",
       "1        1     2034                Broye    Payerne, Caserne d'aviation   \n",
       "2        2     2053               Drance    Martigny, Pont de Rossettan   \n",
       "3        3     2070                 Emme    Emmenmatt, nur Hauptstation   \n",
       "4        4     2078          Poschiavino  Le Prese, stazione principale   \n",
       "..     ...      ...                  ...                            ...   \n",
       "268    336     4329       Hintere Frenke                    Reigoldswil   \n",
       "269    389  FG_0346               Aabach                       Lenzburg   \n",
       "270    391     4502      Stüsslingerbach                        Lostorf   \n",
       "271    401     A093    Weisse Luetschine                    Grindelwald   \n",
       "272    402     A112  Schwarze Luetschine                    Grindelwald   \n",
       "\n",
       "2           Betreiber H_MIN H_MAX H_MEAN catchment_name  \n",
       "0                BAFU   570  4273   2131      BAFU-2019  \n",
       "1                BAFU   440  1514    721      BAFU-2034  \n",
       "2                BAFU   478  4312   2247      BAFU-2053  \n",
       "3                BAFU   639  2221   1070      BAFU-2070  \n",
       "4                BAFU   965  3891   2126      BAFU-2078  \n",
       "..                ...   ...   ...    ...            ...  \n",
       "268  BASEL LANDSCHAFT   486  1168    735        BL-4329  \n",
       "269            AARGAU   392   878    563      AGFG-0346  \n",
       "270         SOLOTHURN   416   957    575        SO-4502  \n",
       "271              BERN   992  4107   2686        BE-A093  \n",
       "272              BERN   980  3745   2197        BE-A112  \n",
       "\n",
       "[273 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catchment_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a28f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catchment_names = df_catchment_names[df_catchment_names['GIS_ID'].apply(lambda x : (x in ALL_GIS_IDs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b8bae",
   "metadata": {},
   "source": [
    "# PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9856c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if True:\n",
    "    from geopy.geocoders import Nominatim\n",
    "    geolocator = Nominatim(user_agent='myapplication')\n",
    "\n",
    "    def get_latitude(name_station):\n",
    "        location = geolocator.geocode(name_station)\n",
    "        try:\n",
    "            return location.raw['lat']\n",
    "        except:\n",
    "            print(name_station)\n",
    "            return 'NAN'\n",
    "    latitudes = list(map(lambda x: get_latitude(x), df_catchment_names['Gewaesser']))\n",
    "    dic_latitudes = {}\n",
    "    for i in range(len(df_catchment_names['Gewaesser'])):\n",
    "        dic_latitudes[df_catchment_names['GIS_ID'].iloc[i]] = latitudes[i]\n",
    "    with open('../data/real_data/dic_latitudes.pkl', 'wb') as handle:\n",
    "        pickle.dump(dic_latitudes, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('../data/real_data/dic_latitudes.pkl', 'rb') as handle:\n",
    "        dic_latitudes = pickle.load(handle)\n",
    "    #latitudes = np.load('/mydata/watres/quentin/code/FLOW/data/latitudes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dcf612b-55e4-4e0c-b4e7-bf9ed38f884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>org_ID</th>\n",
       "      <th>Gewaesser</th>\n",
       "      <th>Station</th>\n",
       "      <th>Betreiber</th>\n",
       "      <th>H_MIN</th>\n",
       "      <th>H_MAX</th>\n",
       "      <th>H_MEAN</th>\n",
       "      <th>catchment_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>2300</td>\n",
       "      <td>Minster</td>\n",
       "      <td>Euthal, Rüti</td>\n",
       "      <td>BAFU</td>\n",
       "      <td>890</td>\n",
       "      <td>2282</td>\n",
       "      <td>1351</td>\n",
       "      <td>BAFU-2300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "2  GIS_ID org_ID Gewaesser       Station Betreiber H_MIN H_MAX H_MEAN  \\\n",
       "43     44   2300   Minster  Euthal, Rüti      BAFU   890  2282   1351   \n",
       "\n",
       "2  catchment_name  \n",
       "43      BAFU-2300  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dic_latitudes))\n",
    "df_catchment_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa1033af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of catchments:  1\n",
      "Add Latitudes\n",
      "Number of catchments:  1\n",
      "Remove catchments with data issues\n",
      "Number of catchments:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10170/2743356347.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_catchment_names['latitude'] = [dic_latitudes[GISID] for GISID in df_catchment_names['GIS_ID']]\n"
     ]
    }
   ],
   "source": [
    "df_catchment_names['latitude'] = [dic_latitudes[GISID] for GISID in df_catchment_names['GIS_ID']]\n",
    "print('Number of catchments: ', df_catchment_names.shape[0])\n",
    "print('Add Latitudes')\n",
    "df_catchment_names = df_catchment_names.drop(df_catchment_names[df_catchment_names['latitude'] == 'NAN'].index)\n",
    "print('Number of catchments: ', df_catchment_names.shape[0])\n",
    "\n",
    "# Filter catchment with data issues\n",
    "locations_pb = df_info.dropna(subset=['INFO'])['GIS_ID'].to_numpy()\n",
    "print('Remove catchments with data issues')\n",
    "df_catchment_names = df_catchment_names[df_catchment_names['GIS_ID'].apply(lambda x: not(x in locations_pb))]\n",
    "print('Number of catchments: ', df_catchment_names.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ff129df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PET_hargreaves(tmin,tmean,tmax,Date,latitude):\n",
    "    lat = pyeto.deg2rad(float(latitude))  # Convert latitude to radians\n",
    "    day_of_year = Date.timetuple().tm_yday\n",
    "    sol_dec = pyeto.sol_dec(day_of_year)            # Solar declination\n",
    "    sha = pyeto.sunset_hour_angle(lat, sol_dec)\n",
    "    ird = pyeto.inv_rel_dist_earth_sun(day_of_year)\n",
    "    et_rad = pyeto.et_rad(lat, sol_dec, sha, ird)   # Extraterrestrial radiation\n",
    "    tmax = max(tmax,tmin)\n",
    "    tmin = min(tmin,tmax)\n",
    "    tmean = max(min(tmean,tmax),tmin)\n",
    "    return pyeto.hargreaves(tmin, tmax, tmean, et_rad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8077a1",
   "metadata": {},
   "source": [
    "# Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e680ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_precip(GISID):\n",
    "    path_fluxes = path_J + '{0}.csv'.format(GISID)\n",
    "    path_hydro = path_Q + '{0}.csv'.format(GISID)\n",
    "    fluxes = pd.read_csv(path_fluxes, sep=\",\")\n",
    "    fluxes['datetime'] = fluxes['datetime'].apply(lambda x: datetime.strptime(str(x), '%Y%m%d%H%M%S'))\n",
    "    fluxes = fluxes.sort_values(by='datetime', ascending=True)\n",
    "    fluxes['t'] = np.array([toYearFraction(t) for t in fluxes['datetime']])\n",
    "    fluxes = fluxes.sort_values(by=['datetime'])\n",
    "    fluxes = fluxes.reset_index()\n",
    "    fluxes = fluxes[['mean', 'datetime', 't']]\n",
    "    fluxes = fluxes.rename(columns={\"mean\": \"precip\"})\n",
    "\n",
    "    dayfluxes = pd.read_csv(path_daily+'sw_rainfall_timeseries/psw_{0}.csv'.format(GISID), sep=\",\")\n",
    "    dayfluxes['datetime'] = dayfluxes['datetime'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%d'))\n",
    "\n",
    "    diffhour = (fluxes['datetime'].diff() > pd.to_timedelta('1 hour')).to_numpy()\n",
    "    idxs = np.where(diffhour>0.5)[0]\n",
    "\n",
    "    missing_dates_as_day = []\n",
    "    for idx in idxs:\n",
    "        current_date_hour = fluxes.iloc[idx-1]['datetime']\n",
    "        next_date = (fluxes.iloc[idx]['datetime']+ pd.to_timedelta('24 hour')).date()\n",
    "        while current_date_hour.date()!=next_date:\n",
    "            date = current_date_hour.date()\n",
    "            day_idx = np.where(dayfluxes['datetime'].apply(lambda x:x.date())==date)[0]\n",
    "            if len(day_idx)==1:\n",
    "                precipday = dayfluxes.iloc[day_idx[0]]['precip']\n",
    "                missing_dates_in_hour = []\n",
    "                date_in_hour = datetime.strptime(str(date), '%Y-%m-%d')\n",
    "                for j in range(24):\n",
    "                    idx_date_in_hour = np.where(fluxes['datetime']==date_in_hour)[0]\n",
    "                    if len(idx_date_in_hour)==0:\n",
    "                        missing_dates_in_hour.append(date_in_hour)\n",
    "                    else:\n",
    "                        precipday = precipday - fluxes.iloc[idx_date_in_hour[0]]['precip']\n",
    "                        precipday = max(0,precipday) \n",
    "                    date_in_hour = pd.to_timedelta('1 hour') + date_in_hour\n",
    "\n",
    "                for date_in_hour in missing_dates_in_hour:\n",
    "                    idx_date_in_hour = np.where(fluxes['datetime']==date_in_hour)[0]\n",
    "                    new_row = {'datetime':date_in_hour, 't':toYearFraction(date_in_hour), 'precip': precipday/len(missing_dates_in_hour) }\n",
    "                    fluxes = pd.concat([fluxes, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            else:\n",
    "                missing_dates_as_day.append(date)\n",
    "\n",
    "\n",
    "            current_date_hour = current_date_hour + pd.to_timedelta('24 hour')\n",
    "\n",
    "    fluxes = fluxes.sort_values(by=['datetime']) \n",
    "    fluxes = fluxes.reset_index(drop=True)\n",
    "\n",
    "    idxlow = np.where([date<=datetime.strptime('2010-01-01', '%Y-%m-%d').date() for date in missing_dates_as_day])[0]\n",
    "    if len(idxlow)!=0:\n",
    "        datelow = np.array(missing_dates_as_day)[idxlow][-1]\n",
    "        datelow = datelow + pd.to_timedelta('24 hour')\n",
    "        fluxes = fluxes[fluxes['datetime']>=datetime.strptime(str(datelow), '%Y-%m-%d')]\n",
    "        fluxes = fluxes.sort_values(by=['datetime']) \n",
    "        fluxes = fluxes.reset_index(drop=True)\n",
    "\n",
    "    idxup = np.where([date>=datetime.strptime('2010-01-01', '%Y-%m-%d').date() for date in missing_dates_as_day])[0]\n",
    "    if len(idxup)!=0:\n",
    "        dateup = np.array(missing_dates_as_day)[idxup][0]\n",
    "        dateup = dateup - pd.to_timedelta('24 hour')\n",
    "        fluxes = fluxes[fluxes['datetime']<=datetime.strptime(str(dateup), '%Y-%m-%d')]\n",
    "        fluxes = fluxes.sort_values(by=['datetime']) \n",
    "        fluxes = fluxes.reset_index(drop=True)\n",
    "    \n",
    "    return fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ba8e23",
   "metadata": {},
   "source": [
    "# Streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2196b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hydro(GISID):\n",
    "    files = os.listdir(path_Q)\n",
    "    cat_name = df_catchment_names[df_catchment_names['GIS_ID']==GISID]['catchment_name'].values[0]\n",
    "\n",
    "    idx_file = np.where([(cat_name in file) for file in files])[0][0]\n",
    "    file = files[idx_file]\n",
    "\n",
    "    hydro = pd.read_csv(path_Q+file, sep=\",\")\n",
    "    hydro['datetime'] = hydro['datetime'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S'))\n",
    "    hydro = hydro.sort_values(by='datetime', ascending=True)\n",
    "    hydro['t'] = np.array([toYearFraction(t) for t in hydro['datetime']])\n",
    "    hydro = hydro.sort_values(by=['datetime'])\n",
    "    hydro = hydro.reset_index()\n",
    "    hydro = hydro[['cms', 'datetime', 't']]\n",
    "    hydro = hydro.rename(columns={\"cms\": \"discharge\"})\n",
    "\n",
    "\n",
    "    dayhydro = pd.read_csv(path_daily+'sw_hydrographs/sw_{0}.csv'.format(GISID), sep=\",\")\n",
    "    dayhydro['datetime'] = dayhydro['datetime'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%d'))\n",
    "\n",
    "    diffhour = (hydro['datetime'].diff() > pd.to_timedelta('1 hour')).to_numpy()\n",
    "    idxs = np.where(diffhour>0.5)[0]\n",
    "    \n",
    "    missing_dates_as_day = []\n",
    "    for idx in idxs:\n",
    "        current_date_hour = hydro.iloc[idx-1]['datetime']\n",
    "        next_date = (hydro.iloc[idx]['datetime']+ pd.to_timedelta('24 hour')).date()\n",
    "        while current_date_hour.date()!=next_date:\n",
    "            date = current_date_hour.date()\n",
    "            day_idx = np.where(dayhydro['datetime'].apply(lambda x:x.date())==date)[0]\n",
    "            if len(day_idx)==1:\n",
    "                dischargeday = dayhydro.iloc[day_idx[0]]['discharge']\n",
    "                missing_dates_in_hour = []\n",
    "                date_in_hour = datetime.strptime(str(date), '%Y-%m-%d')\n",
    "                for j in range(24):\n",
    "                    idx_date_in_hour = np.where(hydro['datetime']==date_in_hour)[0]\n",
    "                    if len(idx_date_in_hour)==0:\n",
    "                        missing_dates_in_hour.append(date_in_hour)\n",
    "                    else:\n",
    "                        dischargeday = dischargeday - hydro.iloc[idx_date_in_hour[0]]['discharge']\n",
    "                        dischargeday = max(0,dischargeday) \n",
    "                    date_in_hour = pd.to_timedelta('1 hour') + date_in_hour\n",
    "\n",
    "                for date_in_hour in missing_dates_in_hour:\n",
    "                    idx_date_in_hour = np.where(hydro['datetime']==date_in_hour)[0]\n",
    "                    new_row = {'datetime':date_in_hour, 't':toYearFraction(date_in_hour), 'discharge': dischargeday/len(missing_dates_in_hour) }\n",
    "                    hydro = pd.concat([hydro, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            else:\n",
    "                missing_dates_as_day.append(date)\n",
    "\n",
    "\n",
    "            current_date_hour = current_date_hour + pd.to_timedelta('24 hour')\n",
    "\n",
    "    hydro = hydro.sort_values(by=['datetime']) \n",
    "    hydro = hydro.reset_index(drop=True)\n",
    "\n",
    "    idxlow = np.where([date<=datetime.strptime('2010-01-01', '%Y-%m-%d').date() for date in missing_dates_as_day])[0]\n",
    "    if len(idxlow)!=0:\n",
    "        datelow = np.array(missing_dates_as_day)[idxlow][-1]\n",
    "        datelow = datelow + pd.to_timedelta('24 hour')\n",
    "        hydro = hydro[hydro['datetime']>=datetime.strptime(str(datelow), '%Y-%m-%d')]\n",
    "        hydro = hydro.sort_values(by=['datetime']) \n",
    "        hydro = hydro.reset_index(drop=True)\n",
    "\n",
    "    idxup = np.where([date>=datetime.strptime('2010-01-01', '%Y-%m-%d').date() for date in missing_dates_as_day])[0]\n",
    "    if len(idxup)!=0:\n",
    "        dateup = np.array(missing_dates_as_day)[idxup][0]\n",
    "        dateup = dateup - pd.to_timedelta('24 hour')\n",
    "        hydro = hydro[hydro['datetime']<=datetime.strptime(str(dateup), '%Y-%m-%d')]\n",
    "        hydro = hydro.sort_values(by=['datetime']) \n",
    "        hydro = hydro.reset_index(drop=True)\n",
    "\n",
    "    return hydro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a72a1",
   "metadata": {},
   "source": [
    "# Merging the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6021e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_dfs(fluxes, hydro):\n",
    "    mindate = hydro['datetime'].to_numpy()[0]\n",
    "    mindate = max(mindate, fluxes['datetime'].to_numpy()[0])\n",
    "\n",
    "    maxdate = hydro['datetime'].to_numpy()[-1]\n",
    "    maxdate = min(maxdate, fluxes['datetime'].to_numpy()[-1])\n",
    "    hydro = hydro[hydro['datetime']>=mindate]\n",
    "    hydro = hydro[hydro['datetime']<=maxdate]\n",
    "    hydro = hydro.sort_values(by=['datetime']) \n",
    "    hydro = hydro.reset_index(drop=True)\n",
    "\n",
    "    fluxes = fluxes[fluxes['datetime']>=mindate]\n",
    "    fluxes = fluxes[fluxes['datetime']<=maxdate]\n",
    "    fluxes = fluxes.sort_values(by=['datetime']) \n",
    "    fluxes = fluxes.reset_index(drop=True)\n",
    "\n",
    "    dfdata = {'discharge':hydro['discharge'].to_numpy(),\n",
    "              'precip': fluxes['precip'].to_numpy(),\n",
    "              't': fluxes['t'].to_numpy(),\n",
    "              'datetime': fluxes['datetime'].to_numpy()}\n",
    "    dfdata = pd.DataFrame(dfdata)\n",
    "    return dfdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0a2e15",
   "metadata": {},
   "source": [
    "# Processing all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05461825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:14, 14.62s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for index, row in tqdm(df_catchment_names.iterrows()):\n",
    "        GISID = row['GIS_ID']\n",
    "        hydro = process_hydro(GISID)\n",
    "        fluxes = process_precip(GISID)\n",
    "        data = merging_dfs(fluxes, hydro)\n",
    "    \n",
    "        # Temperature\n",
    "        Tmax = pd.read_csv(path_daily+'Tmax/TmaxD_GIS_ID-{0}.csv'.format(GISID), header=0,  engine='python')[['mean','datetime']]\n",
    "        Tmax['datetime'] = Tmax['datetime'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%d'))\n",
    "        Tmax = Tmax.rename(columns={'mean': 'tmax'})\n",
    "        Tmax.sort_values(by=['datetime'])\n",
    "        Tmin = pd.read_csv(path_daily+'Tmin/TminD_GIS_ID-{0}.csv'.format(GISID), header=0,  engine='python')[['mean','datetime']]\n",
    "        Tmin['datetime'] = Tmin['datetime'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%d'))\n",
    "        Tmin.sort_values(by=['datetime'])\n",
    "        Tmin = Tmin.rename(columns={'mean': 'tmin'})\n",
    "        Tabs = pd.read_csv(path_daily+'Tabs/TabsD_GIS_ID-{0}.csv'.format(GISID), header=0,  engine='python')[['mean','datetime']]\n",
    "        Tabs['datetime'] = Tabs['datetime'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%d'))\n",
    "        Tabs.sort_values(by=['datetime'])\n",
    "        Tabs = Tabs.rename(columns={'mean': 'tabs'})\n",
    "    \n",
    "        data_daily = Tmin\n",
    "        data_daily = pd.merge(data_daily, Tmax, on=\"datetime\", how=\"inner\")\n",
    "        data_daily = pd.merge(data_daily, Tabs, on=\"datetime\", how=\"inner\")\n",
    "    \n",
    "        # PET\n",
    "        lst = np.arange(0,len(data_daily),1)\n",
    "        PET = np.array(list(map(lambda t: get_PET_hargreaves(data_daily.iloc[t]['tmin'], data_daily.iloc[t]['tabs'], data_daily.iloc[t]['tmax'], data_daily['datetime'][t], dic_latitudes[GISID]), lst) ))\n",
    "        data_daily['pet'] = PET\n",
    "        data_daily.set_index('datetime', inplace=True)\n",
    "        data_hourly = data_daily.resample('H').ffill()\n",
    "        data = pd.merge(data, data_hourly, on=\"datetime\", how=\"inner\")\n",
    "        data.to_csv('../data/real_data/GISID2hourly_data_withPET/{0}.csv'.format(GISID), index=False, header=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e57576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discharge</th>\n",
       "      <th>precip</th>\n",
       "      <th>t</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tabs</th>\n",
       "      <th>pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.350167</td>\n",
       "      <td>0.229430</td>\n",
       "      <td>2005.000114</td>\n",
       "      <td>2005-01-01 00:00:00</td>\n",
       "      <td>-2.403909</td>\n",
       "      <td>3.026066</td>\n",
       "      <td>0.379802</td>\n",
       "      <td>0.540212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.077918</td>\n",
       "      <td>2005.000228</td>\n",
       "      <td>2005-01-01 01:00:00</td>\n",
       "      <td>-2.403909</td>\n",
       "      <td>3.026066</td>\n",
       "      <td>0.379802</td>\n",
       "      <td>0.540212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.351833</td>\n",
       "      <td>0.094607</td>\n",
       "      <td>2005.000342</td>\n",
       "      <td>2005-01-01 02:00:00</td>\n",
       "      <td>-2.403909</td>\n",
       "      <td>3.026066</td>\n",
       "      <td>0.379802</td>\n",
       "      <td>0.540212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.264169</td>\n",
       "      <td>2005.000457</td>\n",
       "      <td>2005-01-01 03:00:00</td>\n",
       "      <td>-2.403909</td>\n",
       "      <td>3.026066</td>\n",
       "      <td>0.379802</td>\n",
       "      <td>0.540212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.353167</td>\n",
       "      <td>0.181210</td>\n",
       "      <td>2005.000571</td>\n",
       "      <td>2005-01-01 04:00:00</td>\n",
       "      <td>-2.403909</td>\n",
       "      <td>3.026066</td>\n",
       "      <td>0.379802</td>\n",
       "      <td>0.540212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136580</th>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.581626</td>\n",
       "      <td>2020-07-31 20:00:00</td>\n",
       "      <td>15.530965</td>\n",
       "      <td>26.443121</td>\n",
       "      <td>21.434227</td>\n",
       "      <td>4.725457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136581</th>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.581740</td>\n",
       "      <td>2020-07-31 21:00:00</td>\n",
       "      <td>15.530965</td>\n",
       "      <td>26.443121</td>\n",
       "      <td>21.434227</td>\n",
       "      <td>4.725457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136582</th>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.581853</td>\n",
       "      <td>2020-07-31 22:00:00</td>\n",
       "      <td>15.530965</td>\n",
       "      <td>26.443121</td>\n",
       "      <td>21.434227</td>\n",
       "      <td>4.725457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136583</th>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.581967</td>\n",
       "      <td>2020-07-31 23:00:00</td>\n",
       "      <td>15.530965</td>\n",
       "      <td>26.443121</td>\n",
       "      <td>21.434227</td>\n",
       "      <td>4.725457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136584</th>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020.582081</td>\n",
       "      <td>2020-08-01 00:00:00</td>\n",
       "      <td>13.723001</td>\n",
       "      <td>23.824591</td>\n",
       "      <td>19.304245</td>\n",
       "      <td>4.283926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136585 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        discharge    precip            t            datetime       tmin  \\\n",
       "0        0.350167  0.229430  2005.000114 2005-01-01 00:00:00  -2.403909   \n",
       "1        0.351000  0.077918  2005.000228 2005-01-01 01:00:00  -2.403909   \n",
       "2        0.351833  0.094607  2005.000342 2005-01-01 02:00:00  -2.403909   \n",
       "3        0.352500  0.264169  2005.000457 2005-01-01 03:00:00  -2.403909   \n",
       "4        0.353167  0.181210  2005.000571 2005-01-01 04:00:00  -2.403909   \n",
       "...           ...       ...          ...                 ...        ...   \n",
       "136580   0.618667  0.000000  2020.581626 2020-07-31 20:00:00  15.530965   \n",
       "136581   0.611667  0.000000  2020.581740 2020-07-31 21:00:00  15.530965   \n",
       "136582   0.607000  0.000000  2020.581853 2020-07-31 22:00:00  15.530965   \n",
       "136583   0.605000  0.000000  2020.581967 2020-07-31 23:00:00  15.530965   \n",
       "136584   0.599000  0.000000  2020.582081 2020-08-01 00:00:00  13.723001   \n",
       "\n",
       "             tmax       tabs       pet  \n",
       "0        3.026066   0.379802  0.540212  \n",
       "1        3.026066   0.379802  0.540212  \n",
       "2        3.026066   0.379802  0.540212  \n",
       "3        3.026066   0.379802  0.540212  \n",
       "4        3.026066   0.379802  0.540212  \n",
       "...           ...        ...       ...  \n",
       "136580  26.443121  21.434227  4.725457  \n",
       "136581  26.443121  21.434227  4.725457  \n",
       "136582  26.443121  21.434227  4.725457  \n",
       "136583  26.443121  21.434227  4.725457  \n",
       "136584  23.824591  19.304245  4.283926  \n",
       "\n",
       "[136585 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049f7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
